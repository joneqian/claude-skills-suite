{
  "url": "https://docs.nestjs.com/microservices/kafka",
  "title": "",
  "content": "Kafka is an open source, distributed streaming platform which has three key capabilities:\n\nThe Kafka project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. It integrates very well with Apache Storm and Spark for real-time streaming data analysis.\n\nTo start building Kafka-based microservices, first install the required package:\n\nLike other Nest microservice transport layer implementations, you select the Kafka transporter mechanism using the transport property of the options object passed to the createMicroservice() method, along with an optional options property, as shown below:\n\nThe options property is specific to the chosen transporter. The Kafka transporter exposes the properties described below.\n\nThere is a small difference in Kafka compared to other microservice transporters. Instead of the ClientProxy class, we use the ClientKafkaProxy class.\n\nLike other microservice transporters, you have several options for creating a ClientKafkaProxy instance.\n\nOne method for creating an instance is to use the ClientsModule. To create a client instance with the ClientsModule, import it and use the register() method to pass an options object with the same properties shown above in the createMicroservice() method, as well as a name property to be used as the injection token. Read more about ClientsModulehere.\n\nOther options to create a client (either ClientProxyFactory or @Client()) can be used as well. You can read about them here.\n\nUse the @Client() decorator as follows:\n\nThe Kafka microservice message pattern utilizes two topics for the request and reply channels. The ClientKafkaProxy.send() method sends messages with a return address by associating a correlation id, reply topic, and reply partition with the request message. This requires the ClientKafkaProxy instance to be subscribed to the reply topic and assigned to at least one partition before sending a message.\n\nSubsequently, you need to have at least one reply topic partition for every Nest application running. For example, if you are running 4 Nest applications but the reply topic only has 3 partitions, then 1 of the Nest applications will error out when trying to send a message.\n\nWhen new ClientKafkaProxy instances are launched they join the consumer group and subscribe to their respective topics. This process triggers a rebalance of topic partitions assigned to consumers of the consumer group.\n\nNormally, topic partitions are assigned using the round robin partitioner, which assigns topic partitions to a collection of consumers sorted by consumer names which are randomly set on application launch. However, when a new consumer joins the consumer group, the new consumer can be positioned anywhere within the collection of consumers. This creates a condition where pre-existing consumers can be assigned different partitions when the pre-existing consumer is positioned after the new consumer. As a result, the consumers that are assigned different partitions will lose response messages of requests sent before the rebalance.\n\nTo prevent the ClientKafkaProxy consumers from losing response messages, a Nest-specific built-in custom partitioner is utilized. This custom partitioner assigns partitions to a collection of consumers sorted by high-resolution timestamps (process.hrtime()) that are set on application launch.\n\nThe ClientKafkaProxy class provides the subscribeToResponseOf() method. The subscribeToResponseOf() method takes a request's topic name as an argument and adds the derived reply topic name to a collection of reply topics. This method is required when implementing the message pattern.\n\nIf the ClientKafkaProxy instance is created asynchronously, the subscribeToResponseOf() method must be called before calling the connect() method.\n\nNest receives incoming Kafka messages as an object with key, value, and headers properties that have values of type Buffer. Nest then parses these values by transforming the buffers into strings. If the string is \"object like\", Nest attempts to parse the string as JSON. The value is then passed to its associated handler.\n\nNest sends outgoing Kafka messages after a serialization process when publishing events or sending messages. This occurs on arguments passed to the ClientKafkaProxyemit() and send() methods or on values returned from a @MessagePattern method. This serialization \"stringifies\" objects that are not strings or buffers by using JSON.stringify() or the toString() prototype method.\n\nOutgoing messages can also be keyed by passing an object with the key and value properties. Keying messages is important for meeting the co-partitioning requirement.\n\nAdditionally, messages passed in this format can also contain custom headers set in the headers hash property. Header hash property values must be either of type string or type Buffer.\n\nWhile the request-response method is ideal for exchanging messages between services, it is less suitable when your message style is event-based (which in turn is ideal for Kafka) - when you just want to publish events without waiting for a response. In that case, you do not want the overhead required by request-response for maintaining two topics.\n\nCheck out these two sections to learn more about this: Overview: Event-based and Overview: Publishing events.\n\nIn more complex scenarios, you may need to access additional information about the incoming request. When using the Kafka transporter, you can access the KafkaContext object.\n\nTo access the original Kafka IncomingMessage object, use the getMessage() method of the KafkaContext object, as follows:\n\nWhere the IncomingMessage fulfills the following interface:\n\nIf your handler involves a slow processing time for each received message you should consider using the heartbeat callback. To retrieve the heartbeat function, use the getHeartbeat() method of the KafkaContext, as follows:\n\nThe Kafka microservice components append a description of their respective role onto the client.clientId and consumer.groupId options to prevent collisions between Nest microservice client and server components. By default the ClientKafkaProxy components append -client and the ServerKafka components append -server to both of these options. Note how the provided values below are transformed in that way (as shown in the comments).\n\nSince the Kafka microservice message pattern utilizes two topics for the request and reply channels, a reply pattern should be derived from the request topic. By default, the name of the reply topic is the composite of the request topic name with .reply appended.\n\nSimilar to other transporters, all unhandled exceptions are automatically wrapped into an RpcException and converted to a \"user-friendly\" format. However, there are edge-cases when you might want to bypass this mechanism and let exceptions be consumed by the kafkajs driver instead. Throwing an exception when processing a message instructs kafkajs to retry it (redeliver it) which means that even though the message (or event) handler was triggered, the offset won't be committed to Kafka.\n\nFor this, you can use a dedicated class called KafkaRetriableException, as follows:\n\nAlong with the default error handling mechanisms, you can create a custom Exception Filter for Kafka events to manage retry logic. For instance, the example below demonstrates how to skip a problematic event after a configurable number of retries:\n\nThis filter offers a way to retry processing a Kafka event up to a configurable number of times. Once the maximum retries are reached, it triggers a custom skipHandler (if provided) and commits the offset, effectively skipping the problematic event. This allows subsequent events to be processed without interruption.\n\nYou can integrate this filter by adding it to your event handlers:\n\nCommitting offsets is essential when working with Kafka. Per default, messages will be automatically committed after a specific time. For more information visit KafkaJS docs. KafkaContext offers a way to access the active consumer for manually committing offsets. The consumer is the KafkaJS consumer and works as the native KafkaJS implementation.\n\nTo disable auto-committing of messages set autoCommit: false in the run configuration, as follows:\n\nTo get real-time updates on the connection and the state of the underlying driver instance, you can subscribe to the status stream. This stream provides status updates specific to the chosen driver. For the Kafka driver, the status stream emits connected, disconnected, rebalancing, crashed, and stopped events.\n\nSimilarly, you can subscribe to the server's status stream to receive notifications about the server's status.\n\nFor more advanced use cases, you may need to access the underlying producer and consumer instances. This can be useful for scenarios like manually closing the connection or using driver-specific methods. However, keep in mind that for most cases, you shouldn't need to access the driver directly.\n\nTo do so, you can use producer and consumer getters exposed by the ClientKafkaProxy instance.",
  "headings": [
    {
      "level": "h3",
      "text": "Kafka",
      "id": "kafka"
    },
    {
      "level": "h4",
      "text": "Installation#",
      "id": "installation"
    },
    {
      "level": "h4",
      "text": "Overview#",
      "id": "overview"
    },
    {
      "level": "h4",
      "text": "Options#",
      "id": "options"
    },
    {
      "level": "h4",
      "text": "Client#",
      "id": "client"
    },
    {
      "level": "h4",
      "text": "Message pattern#",
      "id": "message-pattern"
    },
    {
      "level": "h4",
      "text": "Message response subscription#",
      "id": "message-response-subscription"
    },
    {
      "level": "h4",
      "text": "Incoming#",
      "id": "incoming"
    },
    {
      "level": "h4",
      "text": "Outgoing#",
      "id": "outgoing"
    },
    {
      "level": "h4",
      "text": "Event-based#",
      "id": "event-based"
    },
    {
      "level": "h4",
      "text": "Context#",
      "id": "context"
    },
    {
      "level": "h4",
      "text": "Naming conventions#",
      "id": "naming-conventions"
    },
    {
      "level": "h4",
      "text": "Retriable exceptions#",
      "id": "retriable-exceptions"
    },
    {
      "level": "h3",
      "text": "Custom exception handling",
      "id": "custom-exception-handling"
    },
    {
      "level": "h4",
      "text": "Commit offsets#",
      "id": "commit-offsets"
    },
    {
      "level": "h4",
      "text": "Instance status updates#",
      "id": "instance-status-updates"
    },
    {
      "level": "h4",
      "text": "Underlying producer and consumer#",
      "id": "underlying-producer-and-consumer"
    }
  ],
  "code_samples": [
    {
      "code": "$ npm i --save kafkajs",
      "language": "bash"
    },
    {
      "code": "const app = await NestFactory.createMicroservice<MicroserviceOptions>(AppModule, {\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      brokers: ['localhost:9092'],\n    }\n  }\n});",
      "language": "typescript"
    },
    {
      "code": "const app = await NestFactory.createMicroservice(AppModule, {\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      brokers: ['localhost:9092'],\n    }\n  }\n});",
      "language": "typescript"
    },
    {
      "code": "@Module({\n  imports: [\n    ClientsModule.register([\n      {\n        name: 'HERO_SERVICE',\n        transport: Transport.KAFKA,\n        options: {\n          client: {\n            clientId: 'hero',\n            brokers: ['localhost:9092'],\n          },\n          consumer: {\n            groupId: 'hero-consumer'\n          }\n        }\n      },\n    ]),\n  ]\n  ...\n})",
      "language": "typescript"
    },
    {
      "code": "@Client({\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      clientId: 'hero',\n      brokers: ['localhost:9092'],\n    },\n    consumer: {\n      groupId: 'hero-consumer'\n    }\n  }\n})\nclient: ClientKafkaProxy;",
      "language": "typescript"
    },
    {
      "code": "onModuleInit() {\n  this.client.subscribeToResponseOf('hero.kill.dragon');\n}",
      "language": "typescript"
    },
    {
      "code": "async onModuleInit() {\n  this.client.subscribeToResponseOf('hero.kill.dragon');\n  await this.client.connect();\n}",
      "language": "typescript"
    },
    {
      "code": "@Controller()\nexport class HeroesController {\n  @MessagePattern('hero.kill.dragon')\n  killDragon(@Payload() message: KillDragonMessage): any {\n    const dragonId = message.dragonId;\n    const items = [\n      { id: 1, name: 'Mythical Sword' },\n      { id: 2, name: 'Key to Dungeon' },\n    ];\n    return items;\n  }\n}",
      "language": "typescript"
    },
    {
      "code": "@Controller()\nexport class HeroesController {\n  @MessagePattern('hero.kill.dragon')\n  killDragon(@Payload() message: KillDragonMessage): any {\n    const realm = 'Nest';\n    const heroId = message.heroId;\n    const dragonId = message.dragonId;\n\n    const items = [\n      { id: 1, name: 'Mythical Sword' },\n      { id: 2, name: 'Key to Dungeon' },\n    ];\n\n    return {\n      headers: {\n        realm\n      },\n      key: heroId,\n      value: items\n    }\n  }\n}",
      "language": "typescript"
    },
    {
      "code": "@Controller()\nexport class HeroesController {\n  @MessagePattern('hero.kill.dragon')\n  killDragon(@Payload() message: KillDragonMessage): any {\n    const realm = 'Nest';\n    const heroId = message.heroId;\n    const dragonId = message.dragonId;\n\n    const items = [\n      { id: 1, name: 'Mythical Sword' },\n      { id: 2, name: 'Key to Dungeon' },\n    ];\n\n    return {\n      headers: {\n        kafka_nestRealm: realm\n      },\n      key: heroId,\n      value: items\n    }\n  }\n}",
      "language": "typescript"
    },
    {
      "code": "@MessagePattern('hero.kill.dragon')\nkillDragon(@Payload() message: KillDragonMessage, @Ctx() context: KafkaContext) {\n  console.log(`Topic: ${context.getTopic()}`);\n}",
      "language": "typescript"
    },
    {
      "code": "@Bind(Payload(), Ctx())\n@MessagePattern('hero.kill.dragon')\nkillDragon(message, context) {\n  console.log(`Topic: ${context.getTopic()}`);\n}",
      "language": "typescript"
    },
    {
      "code": "@MessagePattern('hero.kill.dragon')\nkillDragon(@Payload() message: KillDragonMessage, @Ctx() context: KafkaContext) {\n  const originalMessage = context.getMessage();\n  const partition = context.getPartition();\n  const { headers, timestamp } = originalMessage;\n}",
      "language": "typescript"
    },
    {
      "code": "@Bind(Payload(), Ctx())\n@MessagePattern('hero.kill.dragon')\nkillDragon(message, context) {\n  const originalMessage = context.getMessage();\n  const partition = context.getPartition();\n  const { headers, timestamp } = originalMessage;\n}",
      "language": "typescript"
    },
    {
      "code": "interface IncomingMessage {\n  topic: string;\n  partition: number;\n  timestamp: string;\n  size: number;\n  attributes: number;\n  offset: string;\n  key: any;\n  value: any;\n  headers: Record<string, any>;\n}",
      "language": "typescript"
    },
    {
      "code": "@MessagePattern('hero.kill.dragon')\nasync killDragon(@Payload() message: KillDragonMessage, @Ctx() context: KafkaContext) {\n  const heartbeat = context.getHeartbeat();\n\n  // Do some slow processing\n  await doWorkPart1();\n\n  // Send heartbeat to not exceed the sessionTimeout\n  await heartbeat();\n\n  // Do some slow processing again\n  await doWorkPart2();\n}",
      "language": "typescript"
    },
    {
      "code": "const app = await NestFactory.createMicroservice<MicroserviceOptions>(AppModule, {\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      clientId: 'hero', // hero-server\n      brokers: ['localhost:9092'],\n    },\n    consumer: {\n      groupId: 'hero-consumer' // hero-consumer-server\n    },\n  }\n});",
      "language": "typescript"
    },
    {
      "code": "@Client({\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      clientId: 'hero', // hero-client\n      brokers: ['localhost:9092'],\n    },\n    consumer: {\n      groupId: 'hero-consumer' // hero-consumer-client\n    }\n  }\n})\nclient: ClientKafkaProxy;",
      "language": "typescript"
    },
    {
      "code": "onModuleInit() {\n  this.client.subscribeToResponseOf('hero.get'); // hero.get.reply\n}",
      "language": "typescript"
    },
    {
      "code": "throw new KafkaRetriableException('...');",
      "language": "typescript"
    },
    {
      "code": "import { Catch, ArgumentsHost, Logger } from '@nestjs/common';\nimport { BaseExceptionFilter } from '@nestjs/core';\nimport { KafkaContext } from '../ctx-host';\n\n@Catch()\nexport class KafkaMaxRetryExceptionFilter extends BaseExceptionFilter {\n  private readonly logger = new Logger(KafkaMaxRetryExceptionFilter.name);\n\n  constructor(\n    private readonly maxRetries: number,\n    // Optional custom function executed when max retries are exceeded\n    private readonly skipHandler?: (message: any) => Promise<void>,\n  ) {\n    super();\n  }\n\n  async catch(exception: unknown, host: ArgumentsHost) {\n    const kafkaContext = host.switchToRpc().getContext<KafkaContext>();\n    const message = kafkaContext.getMessage();\n    const currentRetryCount = this.getRetryCountFromContext(kafkaContext);\n\n    if (currentRetryCount >= this.maxRetries) {\n      this.logger.warn(\n        `Max retries (${\n          this.maxRetries\n        }) exceeded for message: ${JSON.stringify(message)}`,\n      );\n\n      if (this.skipHandler) {\n        try {\n          await this.skipHandler(message);\n        } catch (err) {\n          this.logger.error('Error in skipHandler:', err);\n        }\n      }\n\n      try {\n        await this.commitOffset(kafkaContext);\n      } catch (commitError) {\n        this.logger.error('Failed to commit offset:', commitError);\n      }\n      return; // Stop propagating the exception\n    }\n\n    // If retry count is below the maximum, proceed with the default Exception Filter logic\n    super.catch(exception, host);\n  }\n\n  private getRetryCountFromContext(context: KafkaContext): number {\n    const headers = context.getMessage().headers || {};\n    const retryHeader = headers['retryCount'] || headers['retry-count'];\n    return retryHeader ? Number(retryHeader) : 0;\n  }\n\n  private async commitOffset(context: KafkaContext): Promise<void> {\n    const consumer = context.getConsumer && context.getConsumer();\n    if (!consumer) {\n      throw new Error('Consumer instance is not available from KafkaContext.');\n    }\n\n    const topic = context.getTopic && context.getTopic();\n    const partition = context.getPartition && context.getPartition();\n    const message = context.getMessage();\n    const offset = message.offset;\n\n    if (!topic || partition === undefined || offset === undefined) {\n      throw new Error(\n        'Incomplete Kafka message context for committing offset.',\n      );\n    }\n\n    await consumer.commitOffsets([\n      {\n        topic,\n        partition,\n        // When committing an offset, commit the next number (i.e., current offset + 1)\n        offset: (Number(offset) + 1).toString(),\n      },\n    ]);\n  }\n}",
      "language": "typescript"
    },
    {
      "code": "@UseFilters(new KafkaMaxRetryExceptionFilter(5))\nexport class MyEventHandler {\n  @EventPattern('your-topic')\n  async handleEvent(@Payload() data: any, @Ctx() context: KafkaContext) {\n    // Your event processing logic...\n  }\n}",
      "language": "typescript"
    },
    {
      "code": "@EventPattern('user.created')\nasync handleUserCreated(@Payload() data: IncomingMessage, @Ctx() context: KafkaContext) {\n  // business logic\n\n  const { offset } = context.getMessage();\n  const partition = context.getPartition();\n  const topic = context.getTopic();\n  const consumer = context.getConsumer();\n  await consumer.commitOffsets([{ topic, partition, offset }])\n}",
      "language": "typescript"
    },
    {
      "code": "@Bind(Payload(), Ctx())\n@EventPattern('user.created')\nasync handleUserCreated(data, context) {\n  // business logic\n\n  const { offset } = context.getMessage();\n  const partition = context.getPartition();\n  const topic = context.getTopic();\n  const consumer = context.getConsumer();\n  await consumer.commitOffsets([{ topic, partition, offset }])\n}",
      "language": "typescript"
    },
    {
      "code": "const app = await NestFactory.createMicroservice<MicroserviceOptions>(AppModule, {\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      brokers: ['localhost:9092'],\n    },\n    run: {\n      autoCommit: false\n    }\n  }\n});",
      "language": "typescript"
    },
    {
      "code": "const app = await NestFactory.createMicroservice(AppModule, {\n  transport: Transport.KAFKA,\n  options: {\n    client: {\n      brokers: ['localhost:9092'],\n    },\n    run: {\n      autoCommit: false\n    }\n  }\n});",
      "language": "typescript"
    },
    {
      "code": "this.client.status.subscribe((status: KafkaStatus) => {\n  console.log(status);\n});",
      "language": "typescript"
    },
    {
      "code": "const server = app.connectMicroservice<MicroserviceOptions>(...);\nserver.status.subscribe((status: KafkaStatus) => {\n  console.log(status);\n});",
      "language": "typescript"
    },
    {
      "code": "const producer = this.client.producer;\nconst consumer = this.client.consumer;",
      "language": "typescript"
    }
  ],
  "patterns": [],
  "links": [
    "https://docs.nestjs.com/first-steps",
    "https://docs.nestjs.com/controllers",
    "https://docs.nestjs.com/providers",
    "https://docs.nestjs.com/modules",
    "https://docs.nestjs.com/middleware",
    "https://docs.nestjs.com/exception-filters",
    "https://docs.nestjs.com/pipes",
    "https://docs.nestjs.com/guards",
    "https://docs.nestjs.com/interceptors",
    "https://docs.nestjs.com/custom-decorators",
    "https://docs.nestjs.com/fundamentals/custom-providers",
    "https://docs.nestjs.com/fundamentals/async-providers",
    "https://docs.nestjs.com/fundamentals/dynamic-modules",
    "https://docs.nestjs.com/fundamentals/injection-scopes",
    "https://docs.nestjs.com/fundamentals/circular-dependency",
    "https://docs.nestjs.com/fundamentals/module-ref",
    "https://docs.nestjs.com/fundamentals/lazy-loading-modules",
    "https://docs.nestjs.com/fundamentals/execution-context",
    "https://docs.nestjs.com/fundamentals/lifecycle-events",
    "https://docs.nestjs.com/fundamentals/discovery-service",
    "https://docs.nestjs.com/fundamentals/platform-agnosticism",
    "https://docs.nestjs.com/fundamentals/testing",
    "https://docs.nestjs.com/techniques/configuration",
    "https://docs.nestjs.com/techniques/database",
    "https://docs.nestjs.com/techniques/mongodb",
    "https://docs.nestjs.com/techniques/validation",
    "https://docs.nestjs.com/techniques/caching",
    "https://docs.nestjs.com/techniques/serialization",
    "https://docs.nestjs.com/techniques/versioning",
    "https://docs.nestjs.com/techniques/task-scheduling",
    "https://docs.nestjs.com/techniques/queues",
    "https://docs.nestjs.com/techniques/logger",
    "https://docs.nestjs.com/techniques/cookies",
    "https://docs.nestjs.com/techniques/events",
    "https://docs.nestjs.com/techniques/compression",
    "https://docs.nestjs.com/techniques/file-upload",
    "https://docs.nestjs.com/techniques/streaming-files",
    "https://docs.nestjs.com/techniques/http-module",
    "https://docs.nestjs.com/techniques/session",
    "https://docs.nestjs.com/techniques/mvc",
    "https://docs.nestjs.com/techniques/performance",
    "https://docs.nestjs.com/techniques/server-sent-events",
    "https://docs.nestjs.com/security/authentication",
    "https://docs.nestjs.com/security/authorization",
    "https://docs.nestjs.com/security/encryption-and-hashing",
    "https://docs.nestjs.com/security/helmet",
    "https://docs.nestjs.com/security/cors",
    "https://docs.nestjs.com/security/csrf",
    "https://docs.nestjs.com/security/rate-limiting",
    "https://docs.nestjs.com/graphql/quick-start",
    "https://docs.nestjs.com/graphql/resolvers",
    "https://docs.nestjs.com/graphql/mutations",
    "https://docs.nestjs.com/graphql/subscriptions",
    "https://docs.nestjs.com/graphql/scalars",
    "https://docs.nestjs.com/graphql/directives",
    "https://docs.nestjs.com/graphql/interfaces",
    "https://docs.nestjs.com/graphql/unions-and-enums",
    "https://docs.nestjs.com/graphql/field-middleware",
    "https://docs.nestjs.com/graphql/mapped-types",
    "https://docs.nestjs.com/graphql/plugins",
    "https://docs.nestjs.com/graphql/complexity",
    "https://docs.nestjs.com/graphql/extensions",
    "https://docs.nestjs.com/graphql/cli-plugin",
    "https://docs.nestjs.com/graphql/generating-sdl",
    "https://docs.nestjs.com/graphql/sharing-models",
    "https://docs.nestjs.com/graphql/other-features",
    "https://docs.nestjs.com/graphql/federation",
    "https://docs.nestjs.com/websockets/gateways",
    "https://docs.nestjs.com/websockets/exception-filters",
    "https://docs.nestjs.com/websockets/pipes",
    "https://docs.nestjs.com/websockets/guards",
    "https://docs.nestjs.com/websockets/interceptors",
    "https://docs.nestjs.com/websockets/adapter",
    "https://docs.nestjs.com/microservices/basics",
    "https://docs.nestjs.com/microservices/redis",
    "https://docs.nestjs.com/microservices/mqtt",
    "https://docs.nestjs.com/microservices/nats",
    "https://docs.nestjs.com/microservices/rabbitmq",
    "https://docs.nestjs.com/microservices/kafka",
    "https://docs.nestjs.com/microservices/grpc",
    "https://docs.nestjs.com/microservices/custom-transport",
    "https://docs.nestjs.com/microservices/exception-filters",
    "https://docs.nestjs.com/microservices/pipes",
    "https://docs.nestjs.com/microservices/guards",
    "https://docs.nestjs.com/microservices/interceptors",
    "https://docs.nestjs.com/standalone-applications",
    "https://docs.nestjs.com/cli/overview",
    "https://docs.nestjs.com/cli/monorepo",
    "https://docs.nestjs.com/cli/libraries",
    "https://docs.nestjs.com/cli/usages",
    "https://docs.nestjs.com/cli/scripts",
    "https://docs.nestjs.com/openapi/introduction",
    "https://docs.nestjs.com/openapi/types-and-parameters",
    "https://docs.nestjs.com/openapi/operations",
    "https://docs.nestjs.com/openapi/security",
    "https://docs.nestjs.com/openapi/mapped-types",
    "https://docs.nestjs.com/openapi/decorators",
    "https://docs.nestjs.com/openapi/cli-plugin",
    "https://docs.nestjs.com/openapi/other-features",
    "https://docs.nestjs.com/recipes/repl",
    "https://docs.nestjs.com/recipes/crud-generator",
    "https://docs.nestjs.com/recipes/swc",
    "https://docs.nestjs.com/recipes/passport",
    "https://docs.nestjs.com/recipes/hot-reload",
    "https://docs.nestjs.com/recipes/mikroorm",
    "https://docs.nestjs.com/recipes/sql-typeorm",
    "https://docs.nestjs.com/recipes/mongodb",
    "https://docs.nestjs.com/recipes/sql-sequelize",
    "https://docs.nestjs.com/recipes/router-module",
    "https://docs.nestjs.com/recipes/swagger",
    "https://docs.nestjs.com/recipes/terminus",
    "https://docs.nestjs.com/recipes/cqrs",
    "https://docs.nestjs.com/recipes/documentation",
    "https://docs.nestjs.com/recipes/prisma",
    "https://docs.nestjs.com/recipes/sentry",
    "https://docs.nestjs.com/recipes/serve-static",
    "https://docs.nestjs.com/recipes/nest-commander",
    "https://docs.nestjs.com/recipes/async-local-storage",
    "https://docs.nestjs.com/recipes/necord",
    "https://docs.nestjs.com/recipes/suites",
    "https://docs.nestjs.com/faq/serverless",
    "https://docs.nestjs.com/faq/http-adapter",
    "https://docs.nestjs.com/faq/keep-alive-connections",
    "https://docs.nestjs.com/faq/global-prefix",
    "https://docs.nestjs.com/faq/raw-body",
    "https://docs.nestjs.com/faq/hybrid-application",
    "https://docs.nestjs.com/faq/multiple-servers",
    "https://docs.nestjs.com/faq/request-lifecycle",
    "https://docs.nestjs.com/faq/common-errors"
  ]
}