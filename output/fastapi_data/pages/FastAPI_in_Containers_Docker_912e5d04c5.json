{
  "url": "https://fastapi.tiangolo.com/deployment/docker/",
  "title": "FastAPI in Containers - DockerÂ¶",
  "content": "When deploying FastAPI applications a common approach is to build a Linux container image. It's normally done using Docker. You can then deploy that container image in one of a few possible ways.\n\nUsing Linux containers has several advantages including security, replicability, simplicity, and others.\n\nIn a hurry and already know this stuff? Jump to the Dockerfile below ðŸ‘‡.\n\nContainers (mainly Linux containers) are a very lightweight way to package applications including all their dependencies and necessary files while keeping them isolated from other containers (other applications or components) in the same system.\n\nLinux containers run using the same Linux kernel of the host (machine, virtual machine, cloud server, etc). This just means that they are very lightweight (compared to full virtual machines emulating an entire operating system).\n\nThis way, containers consume little resources, an amount comparable to running the processes directly (a virtual machine would consume much more).\n\nContainers also have their own isolated running processes (commonly just one process), file system, and network, simplifying deployment, security, development, etc.\n\nA container is run from a container image.\n\nA container image is a static version of all the files, environment variables, and the default command/program that should be present in a container. Static here means that the container image is not running, it's not being executed, it's only the packaged files and metadata.\n\nIn contrast to a \"container image\" that is the stored static contents, a \"container\" normally refers to the running instance, the thing that is being executed.\n\nWhen the container is started and running (started from a container image) it could create or change files, environment variables, etc. Those changes will exist only in that container, but would not persist in the underlying container image (would not be saved to disk).\n\nA container image is comparable to the program file and contents, e.g. python and some file main.py.\n\nAnd the container itself (in contrast to the container image) is the actual running instance of the image, comparable to a process. In fact, a container is running only when it has a process running (and normally it's only a single process). The container stops when there's no process running in it.\n\nDocker has been one of the main tools to create and manage container images and containers.\n\nAnd there's a public Docker Hub with pre-made official container images for many tools, environments, databases, and applications.\n\nFor example, there's an official Python Image.\n\nAnd there are many other images for different things like databases, for example for:\n\nBy using a pre-made container image it's very easy to combine and use different tools. For example, to try out a new database. In most cases, you can use the official images, and just configure them with environment variables.\n\nThat way, in many cases you can learn about containers and Docker and reuse that knowledge with many different tools and components.\n\nSo, you would run multiple containers with different things, like a database, a Python application, a web server with a React frontend application, and connect them together via their internal network.\n\nAll the container management systems (like Docker or Kubernetes) have these networking features integrated into them.\n\nA container image normally includes in its metadata the default program or command that should be run when the container is started and the parameters to be passed to that program. Very similar to what would be if it was in the command line.\n\nWhen a container is started, it will run that command/program (although you can override it and make it run a different command/program).\n\nA container is running as long as the main process (command or program) is running.\n\nA container normally has a single process, but it's also possible to start subprocesses from the main process, and that way you will have multiple processes in the same container.\n\nBut it's not possible to have a running container without at least one running process. If the main process stops, the container stops.\n\nOkay, let's build something now! ðŸš€\n\nI'll show you how to build a Docker image for FastAPI from scratch, based on the official Python image.\n\nThis is what you would want to do in most cases, for example:\n\nYou would normally have the package requirements for your application in some file.\n\nIt would depend mainly on the tool you use to install those requirements.\n\nThe most common way to do it is to have a file requirements.txt with the package names and their versions, one per line.\n\nYou would of course use the same ideas you read in About FastAPI versions to set the ranges of versions.\n\nFor example, your requirements.txt could look like:\n\nAnd you would normally install those package dependencies with pip, for example:\n\nThere are other formats and tools to define and install package dependencies.\n\nNow in the same project directory create a file Dockerfile with:\n\nReview what each line does by clicking each number bubble in the code. ðŸ‘†\n\nMake sure to always use the exec form of the CMD instruction, as explained below.\n\nThe CMD Docker instruction can be written using two forms:\n\nMake sure to always use the exec form to ensure that FastAPI can shutdown gracefully and lifespan events are triggered.\n\nYou can read more about it in the Docker docs for shell and exec form.\n\nThis can be quite noticeable when using docker compose. See this Docker Compose FAQ section for more technical details: Why do my services take 10 seconds to recreate or stop?.\n\nYou should now have a directory structure like:\n\nIf you are running your container behind a TLS Termination Proxy (load balancer) like Nginx or Traefik, add the option --proxy-headers, this will tell Uvicorn (through the FastAPI CLI) to trust the headers sent by that proxy telling it that the application is running behind HTTPS, etc.\n\nThere's an important trick in this Dockerfile, we first copy the file with the dependencies alone, not the rest of the code. Let me tell you why is that.\n\nDocker and other tools build these container images incrementally, adding one layer on top of the other, starting from the top of the Dockerfile and adding any files created by each of the instructions of the Dockerfile.\n\nDocker and similar tools also use an internal cache when building the image, if a file hasn't changed since the last time building the container image, then it will reuse the same layer created the last time, instead of copying the file again and creating a new layer from scratch.\n\nJust avoiding the copy of files doesn't necessarily improve things too much, but because it used the cache for that step, it can use the cache for the next step. For example, it could use the cache for the instruction that installs dependencies with:\n\nThe file with the package requirements won't change frequently. So, by copying only that file, Docker will be able to use the cache for that step.\n\nAnd then, Docker will be able to use the cache for the next step that downloads and install those dependencies. And here's where we save a lot of time. âœ¨ ...and avoid boredom waiting. ðŸ˜ªðŸ˜†\n\nDownloading and installing the package dependencies could take minutes, but using the cache would take seconds at most.\n\nAnd as you would be building the container image again and again during development to check that your code changes are working, there's a lot of accumulated time this would save.\n\nThen, near the end of the Dockerfile, we copy all the code. As this is what changes most frequently, we put it near the end, because almost always, anything after this step will not be able to use the cache.\n\nNow that all the files are in place, let's build the container image.\n\nNotice the . at the end, it's equivalent to ./, it tells Docker the directory to use to build the container image.\n\nIn this case, it's the same current directory (.).\n\nYou should be able to check it in your Docker container's URL, for example: http://192.168.99.100/items/5?q=somequery or http://127.0.0.1/items/5?q=somequery (or equivalent, using your Docker host).\n\nYou will see something like:\n\nNow you can go to http://192.168.99.100/docs or http://127.0.0.1/docs (or equivalent, using your Docker host).\n\nYou will see the automatic interactive API documentation (provided by Swagger UI):\n\nAnd you can also go to http://192.168.99.100/redoc or http://127.0.0.1/redoc (or equivalent, using your Docker host).\n\nYou will see the alternative automatic documentation (provided by ReDoc):\n\nIf your FastAPI is a single file, for example, main.py without an ./app directory, your file structure could look like this:\n\nThen you would just have to change the corresponding paths to copy the file inside the Dockerfile:\n\nWhen you pass the file to fastapi run it will detect automatically that it is a single file and not part of a package and will know how to import it and serve your FastAPI app. ðŸ˜Ž\n\nLet's talk again about some of the same Deployment Concepts in terms of containers.\n\nContainers are mainly a tool to simplify the process of building and deploying an application, but they don't enforce a particular approach to handle these deployment concepts, and there are several possible strategies.\n\nThe good news is that with each different strategy there's a way to cover all of the deployment concepts. ðŸŽ‰\n\nLet's review these deployment concepts in terms of containers:\n\nIf we focus just on the container image for a FastAPI application (and later the running container), HTTPS normally would be handled externally by another tool.\n\nIt could be another container, for example with Traefik, handling HTTPS and automatic acquisition of certificates.\n\nTraefik has integrations with Docker, Kubernetes, and others, so it's very easy to set up and configure HTTPS for your containers with it.\n\nAlternatively, HTTPS could be handled by a cloud provider as one of their services (while still running the application in a container).\n\nThere is normally another tool in charge of starting and running your container.\n\nIt could be Docker directly, Docker Compose, Kubernetes, a cloud service, etc.\n\nIn most (or all) cases, there's a simple option to enable running the container on startup and enabling restarts on failures. For example, in Docker, it's the command line option --restart.\n\nWithout using containers, making applications run on startup and with restarts can be cumbersome and difficult. But when working with containers in most cases that functionality is included by default. âœ¨\n\nIf you have a cluster of machines with Kubernetes, Docker Swarm Mode, Nomad, or another similar complex system to manage distributed containers on multiple machines, then you will probably want to handle replication at the cluster level instead of using a process manager (like Uvicorn with workers) in each container.\n\nOne of those distributed container management systems like Kubernetes normally has some integrated way of handling replication of containers while still supporting load balancing for the incoming requests. All at the cluster level.\n\nIn those cases, you would probably want to build a Docker image from scratch as explained above, installing your dependencies, and running a single Uvicorn process instead of using multiple Uvicorn workers.\n\nWhen using containers, you would normally have some component listening on the main port. It could possibly be another container that is also a TLS Termination Proxy to handle HTTPS or some similar tool.\n\nAs this component would take the load of requests and distribute that among the workers in a (hopefully) balanced way, it is also commonly called a Load Balancer.\n\nThe same TLS Termination Proxy component used for HTTPS would probably also be a Load Balancer.\n\nAnd when working with containers, the same system you use to start and manage them would already have internal tools to transmit the network communication (e.g. HTTP requests) from that load balancer (that could also be a TLS Termination Proxy) to the container(s) with your app.\n\nWhen working with Kubernetes or similar distributed container management systems, using their internal networking mechanisms would allow the single load balancer that is listening on the main port to transmit communication (requests) to possibly multiple containers running your app.\n\nEach of these containers running your app would normally have just one process (e.g. a Uvicorn process running your FastAPI application). They would all be identical containers, running the same thing, but each with its own process, memory, etc. That way you would take advantage of parallelization in different cores of the CPU, or even in different machines.\n\nAnd the distributed container system with the load balancer would distribute the requests to each one of the containers with your app in turns. So, each request could be handled by one of the multiple replicated containers running your app.\n\nAnd normally this load balancer would be able to handle requests that go to other apps in your cluster (e.g. to a different domain, or under a different URL path prefix), and would transmit that communication to the right containers for that other application running in your cluster.\n\nIn this type of scenario, you probably would want to have a single (Uvicorn) process per container, as you would already be handling replication at the cluster level.\n\nSo, in this case, you would not want to have a multiple workers in the container, for example with the --workers command line option. You would want to have just a single Uvicorn process per container (but probably multiple containers).\n\nHaving another process manager inside the container (as would be with multiple workers) would only add unnecessary complexity that you are most probably already taking care of with your cluster system.\n\nOf course, there are special cases where you could want to have a container with several Uvicorn worker processes inside.\n\nIn those cases, you can use the --workers command line option to set the number of workers that you want to run:\n\nHere are some examples of when that could make sense:\n\nYou could want a process manager in the container if your application is simple enough that can run it on a single server, not a cluster.\n\nYou could be deploying to a single server (not a cluster) with Docker Compose, so you wouldn't have an easy way to manage replication of containers (with Docker Compose) while preserving the shared network and load balancing.\n\nThen you could want to have a single container with a process manager starting several worker processes inside.\n\nThe main point is, none of these are rules written in stone that you have to blindly follow. You can use these ideas to evaluate your own use case and decide what is the best approach for your system, checking out how to manage the concepts of:\n\nIf you run a single process per container you will have a more or less well-defined, stable, and limited amount of memory consumed by each of those containers (more than one if they are replicated).\n\nAnd then you can set those same memory limits and requirements in your configurations for your container management system (for example in Kubernetes). That way it will be able to replicate the containers in the available machines taking into account the amount of memory needed by them, and the amount available in the machines in the cluster.\n\nIf your application is simple, this will probably not be a problem, and you might not need to specify hard memory limits. But if you are using a lot of memory (for example with machine learning models), you should check how much memory you are consuming and adjust the number of containers that runs in each machine (and maybe add more machines to your cluster).\n\nIf you run multiple processes per container you will have to make sure that the number of processes started doesn't consume more memory than what is available.\n\nIf you are using containers (e.g. Docker, Kubernetes), then there are two main approaches you can use.\n\nIf you have multiple containers, probably each one running a single process (for example, in a Kubernetes cluster), then you would probably want to have a separate container doing the work of the previous steps in a single container, running a single process, before running the replicated worker containers.\n\nIf you are using Kubernetes, this would probably be an Init Container.\n\nIf in your use case there's no problem in running those previous steps multiple times in parallel (for example if you are not running database migrations, but just checking if the database is ready yet), then you could also just put them in each container right before starting the main process.\n\nIf you have a simple setup, with a single container that then starts multiple worker processes (or also just one process), then you could run those previous steps in the same container, right before starting the process with the app.\n\nThere used to be an official FastAPI Docker image: tiangolo/uvicorn-gunicorn-fastapi. But it is now deprecated. â›”ï¸\n\nYou should probably not use this base Docker image (or any other similar one).\n\nIf you are using Kubernetes (or others) and you are already setting replication at the cluster level, with multiple containers. In those cases, you are better off building an image from scratch as described above: Build a Docker Image for FastAPI.\n\nAnd if you need to have multiple workers, you can simply use the --workers command line option.\n\nThe Docker image was created when Uvicorn didn't support managing and restarting dead workers, so it was needed to use Gunicorn with Uvicorn, which added quite some complexity, just to have Gunicorn manage and restart the Uvicorn worker processes.\n\nBut now that Uvicorn (and the fastapi command) support using --workers, there's no reason to use a base Docker image instead of building your own (it's pretty much the same amount of code ðŸ˜…).\n\nAfter having a Container (Docker) Image there are several ways to deploy it.\n\nIf you are using uv to install and manage your project, you can follow their uv Docker guide.\n\nUsing container systems (e.g. with Docker and Kubernetes) it becomes fairly straightforward to handle all the deployment concepts:\n\nIn most cases, you probably won't want to use any base image, and instead build a container image from scratch based on the official Python Docker image.\n\nTaking care of the order of instructions in the Dockerfile and the Docker cache you can minimize build times, to maximize your productivity (and avoid boredom). ðŸ˜Ž",
  "headings": [
    {
      "level": "h1",
      "text": "FastAPI in Containers - DockerÂ¶",
      "id": "fastapi-in-containers-docker"
    },
    {
      "level": "h2",
      "text": "What is a ContainerÂ¶",
      "id": "what-is-a-container"
    },
    {
      "level": "h2",
      "text": "What is a Container ImageÂ¶",
      "id": "what-is-a-container-image"
    },
    {
      "level": "h2",
      "text": "Container ImagesÂ¶",
      "id": "container-images"
    },
    {
      "level": "h2",
      "text": "Containers and ProcessesÂ¶",
      "id": "containers-and-processes"
    },
    {
      "level": "h2",
      "text": "Build a Docker Image for FastAPIÂ¶",
      "id": "build-a-docker-image-for-fastapi"
    },
    {
      "level": "h3",
      "text": "Package RequirementsÂ¶",
      "id": "package-requirements"
    },
    {
      "level": "h3",
      "text": "Create the FastAPI CodeÂ¶",
      "id": "create-the-fastapi-code"
    },
    {
      "level": "h3",
      "text": "DockerfileÂ¶",
      "id": "dockerfile"
    },
    {
      "level": "h4",
      "text": "Use CMD - Exec FormÂ¶",
      "id": "use-cmd-exec-form"
    },
    {
      "level": "h4",
      "text": "Directory StructureÂ¶",
      "id": "directory-structure"
    },
    {
      "level": "h4",
      "text": "Behind a TLS Termination ProxyÂ¶",
      "id": "behind-a-tls-termination-proxy"
    },
    {
      "level": "h4",
      "text": "Docker CacheÂ¶",
      "id": "docker-cache"
    },
    {
      "level": "h3",
      "text": "Build the Docker ImageÂ¶",
      "id": "build-the-docker-image"
    },
    {
      "level": "h3",
      "text": "Start the Docker ContainerÂ¶",
      "id": "start-the-docker-container"
    },
    {
      "level": "h2",
      "text": "Check itÂ¶",
      "id": "check-it"
    },
    {
      "level": "h2",
      "text": "Interactive API docsÂ¶",
      "id": "interactive-api-docs"
    },
    {
      "level": "h2",
      "text": "Alternative API docsÂ¶",
      "id": "alternative-api-docs"
    },
    {
      "level": "h2",
      "text": "Build a Docker Image with a Single-File FastAPIÂ¶",
      "id": "build-a-docker-image-with-a-single-file-fastapi"
    },
    {
      "level": "h2",
      "text": "Deployment ConceptsÂ¶",
      "id": "deployment-concepts"
    },
    {
      "level": "h2",
      "text": "HTTPSÂ¶",
      "id": "https"
    },
    {
      "level": "h2",
      "text": "Running on Startup and RestartsÂ¶",
      "id": "running-on-startup-and-restarts"
    },
    {
      "level": "h2",
      "text": "Replication - Number of ProcessesÂ¶",
      "id": "replication-number-of-processes"
    },
    {
      "level": "h3",
      "text": "Load BalancerÂ¶",
      "id": "load-balancer"
    },
    {
      "level": "h3",
      "text": "One Load Balancer - Multiple Worker ContainersÂ¶",
      "id": "one-load-balancer-multiple-worker-containers"
    },
    {
      "level": "h3",
      "text": "One Process per ContainerÂ¶",
      "id": "one-process-per-container"
    },
    {
      "level": "h3",
      "text": "Containers with Multiple Processes and Special CasesÂ¶",
      "id": "containers-with-multiple-processes-and-special-cases"
    },
    {
      "level": "h4",
      "text": "A Simple AppÂ¶",
      "id": "a-simple-app"
    },
    {
      "level": "h4",
      "text": "Docker ComposeÂ¶",
      "id": "docker-compose"
    },
    {
      "level": "h2",
      "text": "MemoryÂ¶",
      "id": "memory"
    },
    {
      "level": "h2",
      "text": "Previous Steps Before Starting and ContainersÂ¶",
      "id": "previous-steps-before-starting-and-containers"
    },
    {
      "level": "h3",
      "text": "Multiple ContainersÂ¶",
      "id": "multiple-containers"
    },
    {
      "level": "h3",
      "text": "Single ContainerÂ¶",
      "id": "single-container"
    },
    {
      "level": "h3",
      "text": "Base Docker ImageÂ¶",
      "id": "base-docker-image"
    },
    {
      "level": "h2",
      "text": "Deploy the Container ImageÂ¶",
      "id": "deploy-the-container-image"
    },
    {
      "level": "h2",
      "text": "Docker Image with uvÂ¶",
      "id": "docker-image-with-uv"
    },
    {
      "level": "h2",
      "text": "RecapÂ¶",
      "id": "recap"
    }
  ],
  "code_samples": [
    {
      "code": "FROM python:3.9\n\nWORKDIR /code\n\nCOPY ./requirements.txt /code/requirements.txt\n\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\nCOPY ./app /code/app\n\nCMD [\"fastapi\", \"run\", \"app/main.py\", \"--port\", \"80\"]\n\n# If running behind a proxy like Nginx or Traefik add --proxy-headers\n# CMD [\"fastapi\", \"run\", \"app/main.py\", \"--port\", \"80\", \"--proxy-headers\"]",
      "language": "sql"
    },
    {
      "code": "fastapi[standard]>=0.113.0,<0.114.0\npydantic>=2.7.0,<3.0.0",
      "language": "unknown"
    },
    {
      "code": "from typing import Union\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q}",
      "language": "python"
    },
    {
      "code": "FROM python:3.9\n\n\nWORKDIR /code\n\n\nCOPY ./requirements.txt /code/requirements.txt\n\n\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\n\nCOPY ./app /code/app\n\n\nCMD [\"fastapi\", \"run\", \"app/main.py\", \"--port\", \"80\"]",
      "language": "sql"
    },
    {
      "code": "# âœ… Do this\nCMD [\"fastapi\", \"run\", \"app/main.py\", \"--port\", \"80\"]",
      "language": "markdown"
    },
    {
      "code": "# â›”ï¸ Don't do this\nCMD fastapi run app/main.py --port 80",
      "language": "markdown"
    },
    {
      "code": ".\nâ”œâ”€â”€ app\nâ”‚Â Â  â”œâ”€â”€ __init__.py\nâ”‚   â””â”€â”€ main.py\nâ”œâ”€â”€ Dockerfile\nâ””â”€â”€ requirements.txt",
      "language": "unknown"
    },
    {
      "code": "CMD [\"fastapi\", \"run\", \"app/main.py\", \"--proxy-headers\", \"--port\", \"80\"]",
      "language": "unknown"
    },
    {
      "code": "COPY ./requirements.txt /code/requirements.txt",
      "language": "unknown"
    },
    {
      "code": "RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt",
      "language": "unknown"
    },
    {
      "code": "COPY ./app /code/app",
      "language": "unknown"
    },
    {
      "code": "{\"item_id\": 5, \"q\": \"somequery\"}",
      "language": "json"
    },
    {
      "code": ".\nâ”œâ”€â”€ Dockerfile\nâ”œâ”€â”€ main.py\nâ””â”€â”€ requirements.txt",
      "language": "unknown"
    },
    {
      "code": "FROM python:3.9\n\nWORKDIR /code\n\nCOPY ./requirements.txt /code/requirements.txt\n\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\n\nCOPY ./main.py /code/\n\n\nCMD [\"fastapi\", \"run\", \"main.py\", \"--port\", \"80\"]",
      "language": "sql"
    },
    {
      "code": "FROM python:3.9\n\nWORKDIR /code\n\nCOPY ./requirements.txt /code/requirements.txt\n\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\nCOPY ./app /code/app\n\n\nCMD [\"fastapi\", \"run\", \"app/main.py\", \"--port\", \"80\", \"--workers\", \"4\"]",
      "language": "sql"
    }
  ],
  "patterns": [
    {
      "description": "This is what you would want to do in most cases, for example:",
      "code": "requirements.txt"
    },
    {
      "description": "And you would normally install those package dependencies with pip, for example:",
      "code": "pip"
    },
    {
      "description": "You should be able to check it in your Docker container's URL, for example: http://192.168.99.100/items/5?q=somequery or http://127.0.0.1/items/5?q=somequery (or equivalent, using your Docker host).",
      "code": "{\"item_id\": 5, \"q\": \"somequery\"}"
    },
    {
      "description": "For example:",
      "code": "uv"
    }
  ],
  "links": [
    "https://fastapi.tiangolo.com/deployment/docker/",
    "https://fastapi.tiangolo.com/deployment/docker/?q=",
    "https://fastapi.tiangolo.com/features/",
    "https://fastapi.tiangolo.com/reference/",
    "https://fastapi.tiangolo.com/python-types/",
    "https://fastapi.tiangolo.com/async/",
    "https://fastapi.tiangolo.com/environment-variables/",
    "https://fastapi.tiangolo.com/virtual-environments/",
    "https://fastapi.tiangolo.com/tutorial/",
    "https://fastapi.tiangolo.com/tutorial/first-steps/",
    "https://fastapi.tiangolo.com/tutorial/path-params/",
    "https://fastapi.tiangolo.com/tutorial/query-params/",
    "https://fastapi.tiangolo.com/tutorial/body/",
    "https://fastapi.tiangolo.com/tutorial/query-params-str-validations/",
    "https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/",
    "https://fastapi.tiangolo.com/tutorial/query-param-models/",
    "https://fastapi.tiangolo.com/tutorial/body-multiple-params/",
    "https://fastapi.tiangolo.com/tutorial/body-fields/",
    "https://fastapi.tiangolo.com/tutorial/body-nested-models/",
    "https://fastapi.tiangolo.com/tutorial/schema-extra-example/",
    "https://fastapi.tiangolo.com/tutorial/extra-data-types/",
    "https://fastapi.tiangolo.com/tutorial/cookie-params/",
    "https://fastapi.tiangolo.com/tutorial/header-params/",
    "https://fastapi.tiangolo.com/tutorial/cookie-param-models/",
    "https://fastapi.tiangolo.com/tutorial/header-param-models/",
    "https://fastapi.tiangolo.com/tutorial/response-model/",
    "https://fastapi.tiangolo.com/tutorial/extra-models/",
    "https://fastapi.tiangolo.com/tutorial/response-status-code/",
    "https://fastapi.tiangolo.com/tutorial/request-forms/",
    "https://fastapi.tiangolo.com/tutorial/request-form-models/",
    "https://fastapi.tiangolo.com/tutorial/request-files/",
    "https://fastapi.tiangolo.com/tutorial/request-forms-and-files/",
    "https://fastapi.tiangolo.com/tutorial/handling-errors/",
    "https://fastapi.tiangolo.com/tutorial/path-operation-configuration/",
    "https://fastapi.tiangolo.com/tutorial/encoder/",
    "https://fastapi.tiangolo.com/tutorial/body-updates/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/classes-as-dependencies/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/sub-dependencies/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/dependencies-in-path-operation-decorators/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/global-dependencies/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/dependencies-with-yield/",
    "https://fastapi.tiangolo.com/tutorial/security/",
    "https://fastapi.tiangolo.com/tutorial/security/first-steps/",
    "https://fastapi.tiangolo.com/tutorial/security/get-current-user/",
    "https://fastapi.tiangolo.com/tutorial/security/simple-oauth2/",
    "https://fastapi.tiangolo.com/tutorial/security/oauth2-jwt/",
    "https://fastapi.tiangolo.com/tutorial/middleware/",
    "https://fastapi.tiangolo.com/tutorial/cors/",
    "https://fastapi.tiangolo.com/tutorial/sql-databases/",
    "https://fastapi.tiangolo.com/tutorial/bigger-applications/",
    "https://fastapi.tiangolo.com/tutorial/background-tasks/",
    "https://fastapi.tiangolo.com/tutorial/metadata/",
    "https://fastapi.tiangolo.com/tutorial/static-files/",
    "https://fastapi.tiangolo.com/tutorial/testing/",
    "https://fastapi.tiangolo.com/tutorial/debugging/",
    "https://fastapi.tiangolo.com/advanced/",
    "https://fastapi.tiangolo.com/advanced/path-operation-advanced-configuration/",
    "https://fastapi.tiangolo.com/advanced/additional-status-codes/",
    "https://fastapi.tiangolo.com/advanced/response-directly/",
    "https://fastapi.tiangolo.com/advanced/custom-response/",
    "https://fastapi.tiangolo.com/advanced/additional-responses/",
    "https://fastapi.tiangolo.com/advanced/response-cookies/",
    "https://fastapi.tiangolo.com/advanced/response-headers/",
    "https://fastapi.tiangolo.com/advanced/response-change-status-code/",
    "https://fastapi.tiangolo.com/advanced/advanced-dependencies/",
    "https://fastapi.tiangolo.com/advanced/security/",
    "https://fastapi.tiangolo.com/advanced/security/oauth2-scopes/",
    "https://fastapi.tiangolo.com/advanced/security/http-basic-auth/",
    "https://fastapi.tiangolo.com/advanced/using-request-directly/",
    "https://fastapi.tiangolo.com/advanced/dataclasses/",
    "https://fastapi.tiangolo.com/advanced/middleware/",
    "https://fastapi.tiangolo.com/advanced/sub-applications/",
    "https://fastapi.tiangolo.com/advanced/behind-a-proxy/",
    "https://fastapi.tiangolo.com/advanced/templates/",
    "https://fastapi.tiangolo.com/advanced/websockets/",
    "https://fastapi.tiangolo.com/advanced/events/",
    "https://fastapi.tiangolo.com/advanced/testing-websockets/",
    "https://fastapi.tiangolo.com/advanced/testing-events/",
    "https://fastapi.tiangolo.com/advanced/testing-dependencies/",
    "https://fastapi.tiangolo.com/advanced/async-tests/",
    "https://fastapi.tiangolo.com/advanced/settings/",
    "https://fastapi.tiangolo.com/advanced/openapi-callbacks/",
    "https://fastapi.tiangolo.com/advanced/openapi-webhooks/",
    "https://fastapi.tiangolo.com/advanced/wsgi/",
    "https://fastapi.tiangolo.com/advanced/generate-clients/",
    "https://fastapi.tiangolo.com/fastapi-cli/",
    "https://fastapi.tiangolo.com/deployment/",
    "https://fastapi.tiangolo.com/deployment/versions/",
    "https://fastapi.tiangolo.com/deployment/fastapicloud/",
    "https://fastapi.tiangolo.com/deployment/https/",
    "https://fastapi.tiangolo.com/deployment/manually/",
    "https://fastapi.tiangolo.com/deployment/concepts/",
    "https://fastapi.tiangolo.com/deployment/cloud/",
    "https://fastapi.tiangolo.com/deployment/server-workers/",
    "https://fastapi.tiangolo.com/how-to/",
    "https://fastapi.tiangolo.com/how-to/general/",
    "https://fastapi.tiangolo.com/how-to/migrate-from-pydantic-v1-to-pydantic-v2/",
    "https://fastapi.tiangolo.com/how-to/graphql/",
    "https://fastapi.tiangolo.com/how-to/custom-request-and-route/",
    "https://fastapi.tiangolo.com/how-to/conditional-openapi/",
    "https://fastapi.tiangolo.com/how-to/extending-openapi/",
    "https://fastapi.tiangolo.com/how-to/separate-openapi-schemas/",
    "https://fastapi.tiangolo.com/how-to/custom-docs-ui-assets/",
    "https://fastapi.tiangolo.com/how-to/configure-swagger-ui/",
    "https://fastapi.tiangolo.com/how-to/testing-database/",
    "https://fastapi.tiangolo.com/how-to/authentication-error-status-code/",
    "https://fastapi.tiangolo.com/reference/fastapi/",
    "https://fastapi.tiangolo.com/reference/parameters/",
    "https://fastapi.tiangolo.com/reference/status/",
    "https://fastapi.tiangolo.com/reference/uploadfile/",
    "https://fastapi.tiangolo.com/reference/exceptions/",
    "https://fastapi.tiangolo.com/reference/dependencies/",
    "https://fastapi.tiangolo.com/reference/apirouter/",
    "https://fastapi.tiangolo.com/reference/background/",
    "https://fastapi.tiangolo.com/reference/request/",
    "https://fastapi.tiangolo.com/reference/websockets/",
    "https://fastapi.tiangolo.com/reference/httpconnection/",
    "https://fastapi.tiangolo.com/reference/response/",
    "https://fastapi.tiangolo.com/reference/responses/",
    "https://fastapi.tiangolo.com/reference/middleware/",
    "https://fastapi.tiangolo.com/reference/openapi/",
    "https://fastapi.tiangolo.com/reference/openapi/docs/",
    "https://fastapi.tiangolo.com/reference/openapi/models/",
    "https://fastapi.tiangolo.com/reference/security/",
    "https://fastapi.tiangolo.com/reference/encoders/",
    "https://fastapi.tiangolo.com/reference/staticfiles/",
    "https://fastapi.tiangolo.com/reference/templating/",
    "https://fastapi.tiangolo.com/reference/testclient/"
  ]
}